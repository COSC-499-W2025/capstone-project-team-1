# Week 10 Log - Nov 3-9

## What I Did This Week

Swapped the mock dataset out of the TUI and replaced it with the real artifact listings returned by the backend. The upload flow now takes the `zip_id` we get back from the API, calls the new endpoint to fetch the contents of that archive, and renders the actual files/directories inside the interface. I also cleaned up the view logic so the refreshed data can be toggled through without restarting the TUI, which makes it much easier to sanity check new uploads and confirm that the IDs line up with the right archive.

## Status of Last Week's To-Dos

- Hook the TUI upload flow into the AI integration pipeline - In progress (connected the TUI to the backend endpoint so we show live zip contents)
- Parse uploaded zip files to pull the required project information - In progress (pulling the file manifest via `zip_id`, but still need the deeper parsing step)
- Store extracted data locally in the planned storage layer - Not started

## Next Week's To-Dos

1. Let users choose which file or folder from a retrieved zip gets sent through the LLM pipeline
2. Parse the selected artifact and feed it into the portfolio-generation prompts
3. Start persisting parsed output so we can reuse it without re-hitting the API

## Reflection

Seeing live zip contents flow through the TUI was a big morale boost because it proves the upload work is wired into the backend correctly. The next stretch will be all about turning those listings into actionable inputs for the LLM, and once selection and parsing land weâ€™ll finally have a loop that produces portfolio-ready data instead of just surfacing files.
